---
title: "question3"
author: "Ermioni Athanasiadi"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}
library(haven)
library(tidyverse)
library(patchwork)
library(pROC)
library(nlme)
library(data.table)
library(broom)
library(lattice)

```



```{r}
setwd("./../data")

filename <- "alzheimer25.sas7bdat"

dat <- read_sas(filename)
dat_dt <- setDT(read_sas(filename))
```


Data Preparation
```{r reshape}

reshape_dat <- function(dat) {
    dat_long <- dat %>%
        pivot_longer(
            cols = matches("^(bprs|cdrsb|abpet|taupet)\\d+"),
            names_to = c(".value", "time"),
            names_pattern = "(.+)(\\d+)"
        )
    dat_long
}

to_factor <- function(dat) {
    dat <- dat %>%
        mutate(
            sex = as.factor(sex),
            edu = as.factor(edu),
            trial = as.factor(trial),
            job = as.factor(job),
            wzc = as.factor(wzc),
        )
    dat
}

dat <- to_factor(dat)
dat_long <- reshape_dat(dat)


dat_long <- dat_long %>%
    mutate(
        time = as.factor(time),  # levels 0-6
        time.num = as.numeric(time)   # values 1-7
    )




```

```{r}
# Baseline per subject (year 0)
base <- dat_long %>%
  filter(time == 0) %>%
  transmute(
    patid, trial,
    # Age = age, Sex = sex, Edu = edu, BMI = bmi, Job = job, Income = inkomen,
    # ADL = adl, WZC = wzc,
    cdrsb.0 = cdrsb, 
    abpet.0 = abpet, 
    taupet.0 = taupet
  )

# Add baseline + time to all rows
dat_long <- dat_long %>%
  left_join(base, by = c("patid","trial"))

rm(base)
```

Because further below, we want to add nested random effects of patients within trial centers, let's confirm that patients indeed only appear in a single trial center:
```{r}
dat_long %>% select(patid, trial) %>% dplyr::group_by(patid) %>% summarise(n_trials = n_distinct(trial)) %>% summarise(n = n())
# confirmed
```


# *Open Questions*

1) fit with vs. without intercept
2) Sex in or out

# *To Do*


```{r eval=FALSE, include=FALSE}
control_lme <- lmeControl(
  opt = "optim", 
  msMaxIter = 250,       # max iterations of optimizer
  msMaxEval = 400,       # total evaluations
  returnObject = TRUE
)

# ADD: glsControl

### Model evaluation
# AIC()
```

# Q3: Multivariate Model
_Q3. Fit a multivariate model, and find the most parsimonious mean structure which can be used to describe the average evolutions in the data. What covariance structures are applicable in this case ? What is the most parsimonious structure you can find?_

Let's prepare our dataset for the use with nlme. 

We need complete observations per subject
```{r}
dat_long <- dat_long %>%
  mutate(patid = as.factor(patid))

dat_long_cmpl <- dat_long %>% select(patid, bprs, sex, time, age, trial,
                                     edu, bmi, inkomen, job, adl, wzc, 
                                     time.num,
                                     cdrsb, taupet, abpet) %>% na.omit()

dat_long_cmpl <- dat_long_cmpl %>%
  arrange(patid, time)


dat_long_cmpl2 <- dat_long_cmpl %>%
  group_by(patid) %>%
  filter(n() > 1) %>%
  ungroup()

```

Let's have a look at the number of observations per subject:
```{r}
table(dat_long$patid) %>% table()
table(dat_long_cmpl$patid) %>% table()
table(dat_long_cmpl2$patid) %>% table()

# do they add up?
table(dat_long_cmpl$patid) %>% table() %>% sum()

tab <- dat_long_cmpl %>% group_by(patid) %>% summarize(
  patid = n()
)

tab


```
We have n = 1253 subjects in our dataset.

When keeping only subjects with complete observations, we exclude n = 147 persons from our sample.

We have > 1 observation for each subject in our dat_long_compl2. 


#### Preliminary Mean & Variance structure
 ##### Main effects


Remarks about the multivariate model:
It is suitable if only few repeated measurements per subject exist. With up to 6 time points. this may not be the best case with our data.
A multivariate model may be able to handle unequal numbers of measurements per subject (due to missing data).
In R this works: But because the implemented functions require complete data, missing observations are excluded prior to model fitting. 

In the course notes it is mentioned that the balance of data matters when fitting a multivariate model (p.92).

This refers to the number of measurements per subject: In our data, we have quite some unbalance as many subjects drop out over time. But, they are all measured at the same time points, which is good.
The recommendation for unbalanced data is to fit multivariate models only under very specific variance and covariance conditions.
-> Toeplitz and AR(1) are invalid because time points are not equally spaced for all subjects.
-> compound symmetry is valid but based on strong assumptions

###### Estimate model

```{r}
form_full = bprs ~ time.num + age + sex + trial + edu + bmi + inkomen + job + adl + wzc + cdrsb.0 + abpet.0 + taupet.0 

m_full <- gls(
  model = form_full, # - 1: we could also remove the intercept: then no absolute, not relative to bl
  weights = varIdent(form = ~ 1 | time.num),       # different variances per year
  #correlation = corSymm(form = ~ 1 | trial/patid),
  method = "ML",
  data = dat_long,
  na.action = na.exclude#,
  #   control = control_lme
)

summary(m_full)
```
We start with a full model that contains all parameters (fixed effects).

We specify no correlation structure (default is uncorrelated).

But we already allowe for variance heterogeneity by specifying the weights argument. As we discovered this already in the exploratory analysis.



```{r}
# remove intercept

m1 <- gls(
  model = bprs ~ time.num + age + sex + trial + edu + bmi + inkomen + job + adl + wzc + cdrsb.0 + abpet.0 + taupet.0 - 1, 
  weights = varIdent(form = ~ 1 | time.num),       # different variances per year
  #correlation = corSymm(form = ~ 1 | trial/patid),
  method = "ML",
  data = dat_long,
  na.action = na.exclude
)

summary(m1)
```

###### Examine the model fit
```{r}
# fixed effect covariance 
mod <- m_full

vcov_fixed <- round(vcov(mod), 3)
head(vcov_fixed, n = 20)


```
We can check out the covariance matrix for our fixed effects. 

```{r MOVE DOWN TO COVARIANCE SECTION}
# Residual covariance matrix per patient
pat1 <- dat_long$patid == levels(dat_long$patid)[1]

resid_matrix <- getVarCov(m_full, individual = levels(dat_long$patid)[1])
resid_matrix

getVarCov(m_full, individual = levels(dat_long$patid)[2])
getVarCov(m_full, individual = levels(dat_long$patid)[3])

# this shows us that the same var-covar is estimated for each subject

```


In our current model, we have constant covariances that don't vary by patient

```{r DELETE}
mod2 <- m_full

# random effect variance
VarCorr(mod2)
VarCorr(mod2)  # corr = T

# for random effects model, this looks like this:
# patid = pdLogChol(1) 
#             Variance StdDev  
# (Intercept) 3.229688 1.797133
# Residual    3.971972 1.992981

# function not available for gls

```


####### Visualize the model fit 
```{r}

mod <- m_full

plot(mod, resid(., type = "p") ~ fitted(.) | time, abline = 0)
plot(mod, resid(., type = "p") ~ fitted(.) | sex, abline = 0)
# plot(mod, resid(., type = "p") ~ fitted(.) | patid, abline = 0)

plot(mod, age ~ resid(.))



```
```{r}
# now plot residuals by subjects (for subsample)

patid_sample <- dat_long %>%
  distinct(patid) %>%
  slice_sample(n = 30) %>%
  pull(patid)

resids_sample <- resid(mod, type = "p")[dat_long$patid %in% patid_sample]

fitted_sample <- fitted(mod)[dat_long$patid %in% patid_sample]

patid_sample <- dat_long %>% select(patid) %>% filter(patid %in% patid_sample)

# xyplot(resids_sample ~ fitted_sample | factor(patid_sample))

plot(resids_sample ~ fitted_sample)


```

```{r}
qqnorm(resid(mod, type = "p"))
qqline(resid(mod, type = "p"))
```
Looks nice and normal. We dont need any linear transformation of our outcome.

```{r DELETE}
mod <- m_full

## transform the random effects object a bit
ranefs <- ranef(mod)

dat_ranefs <- data.frame(patid = rownames(ranefs), intercept = ranefs[, "(Intercept)"])

hist(dat_ranefs$intercept,
     breaks = 20,
     main = "Random intercepts by patient",
     xlab = "Random intercept",
     col = "grey",
     border = "white")


dotplot(sort(dat_ranefs$intercept),
        main = "Random intercepts of patients",
        xlab = "Random intercept")



ggplot(dat_ranefs, aes(x = reorder(patid, intercept), y = intercept)) +
  geom_point(color = "grey") +
  geom_hline(yintercept = 0, linetype = "dashed") +
  coord_flip() +  # horizontal for readability
  theme_bw() +
  labs(title = "Patient-level random intercepts",
       x = "Patient ID",
       y = "Random intercept")


```

Lets also visualize the residuals to check if our variance structure seems plausible:
```{r}


dat_long$resid_p <- residuals(m_full, type = "pearson")
dat_long$resid_n <- residuals(m_full, type = "normalized")  # standardized res

ggplot(dat_long, aes(x = factor(time.num), y = resid_p)) +
  geom_jitter(alpha = 0.2, width = 0.15) +
  geom_boxplot(outlier.shape = NA, alpha = 0.6) +
  labs(x = "Year", y = "Pearson residuals",
       title = "Residuals by time level") +
  theme_bw()
ggsave("./../figures/q3_resid_p.png", width = 8, height = 6, dpi = 300)

ggplot(dat_long, aes(x = factor(time.num), y = resid_n)) +
  geom_jitter(alpha = 0.2, width = 0.15) +
  geom_boxplot(outlier.shape = NA, alpha = 0.6) +
  labs(x = "Year", y = "Pearson residuals",
       title = "Residuals by time level") +
  theme_bw()
ggsave("./../figures/q3_resid_n.png", width = 8, height = 6, dpi = 300)

years <- c("Year 0", "Year 1", "Year 2", "Year 3", "Year 4", "Year 5", "Year 6")
ggplot(dat_long, aes(x = fitted(m_full), y = resid_n)) +
  geom_point(alpha = 0.3) +
  geom_hline(yintercept = 0) +
  labs(x = "Fitted residuals",
      title = "Standardized residuals vs fitted") +
  theme_bw() 
ggsave("./../figures/q3_resid_vs_fitted.png", width = 8, height = 6, dpi = 300)

q3_resid_vs_fitted_by_year <- plot(m_full, resid(., type = "p") ~ fitted(.) | as.factor(time.num),
     abline = 0, ylab = "Fitted residuals")
png("./../figures/q3_resid_vs_fitted_by_year.png")
print(q3_resid_vs_fitted_by_year)
dev.off()
q3_resid_vs_fitted_by_year

```
Apart from the dropout thats clearly visible, the errors dont look too dissimilar between years. That suggests that we could probably also go for a homoscedastic model.

However, we can see that the errors are more dense/spread out in certain years compared to others. E.g. Years 3 and 6 have a smaller variance.



###### Compare with null model

now lets check how useful our model is compared to the null model
```{r}
m0 <- gls(
  model = bprs ~ 1,
  weights = varIdent(form = ~ 1 | time.num),
  data = dat_long,
  method = "ML",
  na.action = na.exclude
)

anova(m0, m_full)
```

###### Export results
```{r}
# length(m_full$coefficients$fixed)
# noquote(names(m_full$coefficients$fixed))  # add: print as latex table
length(m_full$coefficients)
noquote(names(m_full$coefficients))  # add: print as latex table

```
```{r}


# fit table in html
tab_model(m_full,
          file = "model.html",
          show.r2 = TRUE,
          show.se = TRUE
          # dv.labels = "Response",
          # pred.labels = c("Intercept", "X variable", "Z variable")
          )


# fit table in latex
xtable(summary(m_full)$tTable)
```

```{r}

library(kableExtra)

# kbl(m_full, digits = 3, booktabs = T, escape = F, caption = "Test")

```


#### Selection of Fixed effects
With our preliminary mean structure, we will now try to reduce the model stepwise:
Lets start with the main effects:
##### Main effects
```{r}
m1 <- m_full

m2 <- update(m1, . ~ . - inkomen)
a1 <- anova(m1, m2)  
m1 <- m2 # exclude inkomen

m3 <- update(m1, . ~ . - bmi)
a2 <- anova(m1, m3)

m4 <- update(m1, . ~ . - job)
a3 <- anova(m1, m4) 

m5 <- update(m1, . ~ . - edu)
a4 <- anova(m1, m5)
m1 <- m5 # exclude edu

m6 <- update(m1, . ~ . - wzc)
a5 <- anova(m1, m6)

m7 <- update(m1, . ~ . - adl)
a6 <- anova(m1, m7)
m1 <- m7 # exclude adl

m8 <- update(m1, . ~ . - trial)
a7 <- anova(m1, m8)

m9 <- update(m1, . ~ . - taupet.0)
a8 <- anova(m1, m9)
m1 <- m9  # exclude taupet

m10 <- update(m1, . ~ . - abpet.0)
a9 <- anova(m1, m10)
m1 <- m10 # exclude abpet

m11 <- update(m1, . ~ . - sex)
a10 <- anova(m1, m11)
m1 <- m11  # exclude sex

m12 <- update(m1, . ~ . - age)
a11 <- anova(m1, m12)

m13 <- update(m1, . ~ . - time.num)
a12 <- anova(m1, m13)

m14 <- update(m1, . ~ . - cdrsb.0)
a13 <- anova(m1, m14)

```

The strongest Likelihood Ratios are obtained for time, age and trial. 
We only exclude inkomen and sex as predictors.
*Update* We can also exclude 
- edu
- adl
- taupet.0
- abpet.0



So the most parsimonious model based on Likelihood Inference looks like this

bprs ~ time.num + age + trial + bmi + job + wzc + cdrsb.0


Sidenote: 
If we use the wide format data and do the same model selection but start with an OLS model as fitted with lm() and update it, we get different Likelihood Ratio Test results and different p values than with gls(). So this is probably due to the ignorance of the other outcomes in gls().


###### Export
```{r}

anovas <- mget(paste0("a", seq(1:13)))

anovas_df <- lapply(anovas, function(x) {
    df <- as.data.frame(x)
    df$model <- rownames(x)
    df
    })

tab_anovas <- bind_rows(anovas_df)
rownames(tab_anovas) <- NULL


tab_anovas <- tab_anovas %>% 
    select(-Model, -call) %>% 
    relocate(model, .before = "df") %>%
    mutate(

        p.value.form = ifelse(`p-value` < .001, "< .001", sprintf("%.3f", tab_anovas$`p-value`)),
        across(where(~is.numeric(.)), ~ round(., 2))
    ) %>%
    select(-`p-value`)

tab_anovas <- tab_anovas %>% 
    filter((!is.na(L.Ratio) & !is.na(p.value.form)) | row_number()==1  )


q3_tab_anovas_latex <- tab_anovas %>% 
    kbl(format = "latex", 
                   booktabs = TRUE, 
                   caption = "Likelihood Ratio Tests used for model selection of main effects ",
                   label = "tab:q3_anova_main_effects"
                       ) %>%
    kable_styling(latex_options = c("hold_position"))# %>% 
    #save_kable("q3_anova_maineffects.tex")
# print(q3_tab_anovas_latex)

```

```{r}
# remove objects not needed anymore
rm(a1, a2, a3, a4, a5, a6, a7, a8, a9, a10, a11, a12, a13)
```


##### Interaction effects I
Now lets see if some interactions are meaningful:
```{r}

m_prel <- m1
m_prel_save <- m1 # backup model
```

```{r DELETE}
m1 <- m_prel

# time * age
m2 <- gls(
  model = bprs ~ time.num * age + trial + bmi + job + wzc + cdrsb.0, 
  weights = varIdent(form = ~ 1 | time.num),       # different variances per year
  # correlation = corSymm(form = ~ time.num | patid),
  method = "ML",
  data = dat_long,
  na.action = na.exclude,
  control = control_lme
)

anova(m1, m2)

# time * age * trial
m3 <- gls(
  model = bprs ~ time.num  * trial + bmi + job + wzc + cdrsb.0, 
  weights = varIdent(form = ~ 1 | time.num),       # different variances per year
  # correlation = corSymm(form = ~ time.num | patid),
  method = "ML",
  data = dat_long,
  na.action = na.exclude,
  control = control_lme
)
anova(m1, m3)  # this model is way worse, and we have to fit > 20 additional pars

# time * age * cdrsb.0
m4 <- gls(
  model = bprs ~ time.num * age * cdrsb.0 + trial + bmi + job + wzc, 
  weights = varIdent(form = ~ 1 | time.num),       # different variances per year
  # correlation = corSymm(form = ~ time.num | patid),
  method = "ML",
  data = dat_long,
  na.action = na.exclude,
  control = control_lme
)
anova(m1, m4) 
# we could choose this model, but the Likelihood Ratio is not super large

# time * age * wzc
m5 <- gls(
  model = bprs ~ time.num * age * wzc + trial + bmi + job + cdrsb.0, 
  weights = varIdent(form = ~ 1 | time.num),       # different variances per year
  # correlation = corSymm(form = ~ time.num | patid),
  method = "ML",
  data = dat_long,
  na.action = na.exclude,
  control = control_lme
)
anova(m1, m5)  # does not differ 

# time * (trial + cdrsb.0)
m5 <- gls(
  model = bprs ~ time.num * (trial + cdrsb.0) + age + wzc + trial + bmi + job, 
  weights = varIdent(form = ~ 1 | time.num),       # different variances per year
  # correlation = corSymm(form = ~ time.num | patid),
  method = "ML",
  data = dat_long,
  na.action = na.exclude,
  control = control_lme
)
anova(m1, m5)  # this seems like a nice tradeoff, with not too many additional parameters but improved fit


# rm(m2, m3, m4, m5)

```

The following interactions between time and other predictors seem plausible for our data.

Also possible:
time.num * (trial + cdrsb.0)



##### Non-linear trends
Now lets see if we can detect some non-linear trends
```{r eval=FALSE, include=FALSE}

m6 <- gls(
  model = ##### time.num + I(time_num^2) + age + trial + edu + bmi + job + adl + wzc + cdrsb.0 + abpet.0 + taupet.0, 
  weights = varIdent(form = ~ 1 | time.num),       # different variances per year
  # correlation = corSymm(form = ~ time.num | patid),
  method = "ML",
  data = dat_long,
  na.action = na.exclude,
  control = control_lme
)

anova(m2, m1) 

```
this does not work yet. 

---------------------------------------------------------------------------------

Our current model looks like this: 

bprs ~ time.num + age + trial + bmi + job + wzc + cdrsb.0

lets now refit our model with REML, now that we have fixed the mean structure:
```{r}
form_fixed <- bprs ~ time.num + age + trial + bmi + job + wzc + cdrsb.0
m1 <- gls(
  model = form_fixed, 
  weights = varIdent(form = ~ 1 | time.num),       # different variances per year
  # correlation = corSymm(form = ~ time.num | patid),
  method = "REML",
  data = dat_long,
  na.action = na.exclude,
  control = control_lme
)
```


#### Selection of Covariance Structure

Possible Covariance and Variance Specifications:
 (with ML or REML)
- using only patientid for random intercepts
- Using nested patid in trial
- removing the heterogenous variance weights
- removing the nested trial in the correlation structure AND the variance weights
- allowing separate covariances for different years
- readding the weights

Note about form of the Cor structure:
correlation structure is assumed to apply only to observations within the same grouping level (i.e. within the same patient/trial); observations with different grouping levels (patients) are assumed to be uncorrelated


##### M2
```{r}

# ---- Model 2: without weights

m2 <- gls(
  model = form_fixed, 
  # weights = varIdent(form = ~ 1 | time.num),       # different variances per year, (corresponding SAS argument would be type = VC)
  # correlation = corSymm(form = ~ time.num | patid),
  method = "REML",
  data = dat_long,
  na.action = na.exclude#,
  # control = control_lme
)

summary(m2)
anova(m1, m2)
```
We tested if the model with weights is indeed better.
Ok, we know fitting different variances per year does improve our model fit. Lets stick with this model.

(..........)

##### M3
```{r}
# ---- Model 3: with unstructured errors: every time point has own variance, 
# and all year-pairs can have their own covariance 
# with weights

m3 <- gls(
  model = form_fixed, 
  weights = varIdent(form = ~ 1 | time.num),       # different variances per year
  correlation = corSymm(form = ~ time.num | patid),
  method = "REML",
  data = dat_long,
  na.action = na.exclude#,
  #control = control_lme
)

summary(m3)
anova(m1, m3)
m1 <- m3
```
This improves our model, as expected. we keep the unstructured covariance.



##### M4
```{r}
# without weights but with unstructured corr?

m4 <- gls(
  model = form_fixed, 
  #weights = varIdent(form = ~ 1 | time.num),       # different variances per year
  correlation = corSymm(form = ~ time.num | patid),
  method = "REML",
  data = dat_long,
  na.action = na.exclude#,
  # control-argument
)

summary(m4)
anova(m1, m4)

```

Removing the weights is worse. We keep our model.

Nested factor trial/patid --> this is not possible in the correlation matrix!!!
Because we can only model WITHIN-patient correlations, while the nested structure of patients between different trials (and wanting to estimate how much patients of different trial centers differ) is obviously BETWEEN subjects correlation.

Thus, we can ignore this in the multivariate model. This will only become significant for random effect estimation.

```{r}
# check out the variance
m1$modelStruct$corStruct
```
The correlations dont really decrease that much with increasing lag. Although there is a small trend, but for lag(1,7) its again stronger than for lag(1,6) so we cant be sure. But errors become more correlated the later the time point is.

##### M5
```{r}
# with weights 
# compound symmetry

m5 <- gls(
  model = form_fixed, 
  weights = varIdent(form = ~ 1 | time.num),       # different variances per year
  correlation = corCompSymm(form = ~ time.num | patid),   # compound symmetry within-subject correlation
  method = "REML",
  data = dat_long,
  na.action = na.exclude#,
  # control-argument
)


summary(m5)
anova(m1, m5)
```

The model is worse. So no compound symmetry 

##### M6
```{r}
## ---- Model 6: Autoregressive: decreasing correlations with increasing time lag, stronger ones for adjancent lags
# with weights 

m6 <- gls(
  model = form_fixed, 
  weights = varIdent(form = ~ 1 | time.num),       # different variances per year
  correlation = corAR1(form = ~ time.num | patid),   # identical to corCAR1, because time is numeric
  method = "REML",
  data = dat_long,
  na.action = na.exclude#,
  # control-argument
)



summary(m6)
anova(m1, m6)
```

As we observed earlier, the corr decreases with more lag, but not consistently, for last time point its again stronger. So the AR1 strcture is not better.

#However, the correlation matrix has identical values in all off-diagonal cells, while the covariance matrix shows distinct values. 

The covariance matrix indicates decreasing trends but in the last years increasing again -> explanation?

##### M7
```{r}
# ---- Model 7: Toeplitz (ARMA(6,0)) ----

m7 <- gls(
  model = form_fixed, 
  weights = varIdent(form = ~ 1 | time.num),       # different variances per year
  correlation = corARMA(form = ~ time.num | patid, p = 6, q = 0),
  method = "REML",
  data = dat_long,
  na.action = na.exclude#,
  # control-argument
)


summary(m7)
anova(m1, m7)
```

This model still has worse fit, but not that much worse.

ARMA is a combination of AR und MA models
AR = autoregressive model = dependency of time points on earlier time points
MA = moving average, considers weighted averages of past errors

##### LRTs
```{r}
anova(m2, m3, m4, m5, m6, m7)
```
We can compare the models because they have the same fixed effects, but different variance structures.

The most parsimonious structure we can find is the unstructured one. All more parsimonious ones don't reach the same model fit


Model 6 -> compound symmetry is way worse

But autoregressive and especially Toeplitz are a bit better.

However, how appropriate are they in the case of our data?

If we take the equal time spacing seriously, this may not hold for our data in the context of a clinical trial:

Because patients don’t come exactly at 12, 24, 36, … months.

Example: Typical real-life patterns:
Intended visit	Actual timestamp (months)
0 years	        0.2
1 year	        12.7
2 years	        24.3
3 years	        35.9
4 years	        48.4

*OLD NOTES*
Model 2 with correlated (unstructured) errors improves fit -> We keep the model.
But the problem is, we have missing data in some years --> to apply unstructured covariance structure for errors, we can only use complete observations. But this is the case for other structures, too.

Model 3 imposes an ordering of the correlations based on the time variable -> We can't compare it to the other model anymore because with time as numeric, it uses different number of observations.

Conceptually, the syntax of Model 3 but with time as factor should be equivalent to Model 2 as our time variable is ordered.

Model 4 imposes compound symmetry. 

Model 5 introduces autoregressive correlation structure. It improves model fit, so we keep it. Probably mainly due to the more parsimonious structure.

Model 6 uses the Toeplitz structure.

We can't compare Model 5 and 4 directly, so we have to look at AIC and BIC to get an ide which covariance structure is better.

--> model 3 performs best in a Likelihood Ratio test. but its a complicated structure. If we want to have a more parsimonious one, we could chose between Model4-Model6. 


Summarising the conclusions on variance & covariance structure:
- The AR(1) component captures the temporal correlation in repeated BPRS measures — i.e., scores from adjacent years are more similar than those several years apart.
- The heterogeneous variance (varIdent) allows different variability per year, which is realistic in your study since measurement noise and patient dropout tend to increase over time.
- The significant improvement in log-likelihood and lower AIC/BIC demonstrate that this flexibility meaningfully improves model fit without overfitting.
- This means that correlations between consecutive yearly measurements decay exponentially with time lag, while allowing variability to differ across years



##### Examine (co)variance matrices
Now lets build the correlation and the covariance matrix:
```{r}
mod <- m5

get_cor_matrix <- function(mod) {
  # construct the correlation matrix
  cor_pars <- coef(mod$modelStruct$corStruct, unconstrained = FALSE)
  var_pars <- coef(mod$modelStruct$varStruct, unconstrained = FALSE)  # relative = m-1 pars for m years
  var_pars <- c("1" = 1, var_pars)
  sigma0 <- mod$sigma
  k <- length(var_pars)
  C <- diag(1, k)
  C[lower.tri(C)] <- cor_pars
  C[upper.tri(C)] <- t(C)[upper.tri(C)]
  C <- round(C, 3)
  C
  
}

get_cov_matrix <- function(mod) {
  # compute covariance matrix sigma S = DCD
  var_pars <- coef(mod$modelStruct$varStruct, unconstrained = FALSE)  # relative = m-1 pars for m years
  var_pars <- c("1" = 1, var_pars)
  sigma0 <- mod$sigma
  sd_vars <- sigma0 * sqrt(var_pars)
  D <- diag(sd_vars)
  C <- get_cor_matrix(mod)
  S <- D %*% C %*% D
  S <- round(S, 3)
  S
}


```

```{r}
get_cor_matrix(m1)
get_cov_matrix(m1)
```
Why AR(1) is not good enough for our model fit:
SOme thoughts:
- AR(1) works best with homogeneous data
- it estimates a single corr parameter only
- Lag-1 correlations are increasing over time, not constant. Also referred to as Stationarity assumption. that means that time points which are only 1 lag apart do NOT have the same correlation, but this is a requirement for AR(1): Corr(t,t+1)=ρ for all t. It makes sense for our data though that the measurements are noisier in the beginning.

Reflecting on our assumption of equal time spacing:
Even if study design says “measure every year,” patients don’t come exactly at 12, 24, 36, … months. -> this is unrealistic for our clinical data.

Example: Typical real-life patterns:

Intended visit	Actual timestamp (months)
0 years	0.2
1 year	12.7
2 years	24.3
3 years	35.9
4 years	48.4


#### Robust estimation
```{r}
# error: correct dataset to be used
# coef_test(m_full, vcov = "CR2", cluster = na.exclude(dat_long$time))
```



```{r}

models <- list(m5, m6, m7)

lapply(models, get_cor_matrix)


lapply(models, get_cov_matrix)

```


Let's have a closer look at the variances and correlations of our models:
```{r}
weights <- coef(m.covarstr$modelStruct$varStruct)
summary(m.covarstr)$sigma * weights

```


```{r}
### visualize the variances to find out
```



#### Old: multivariate model fitted with multiple outcomes
```{r}

form_multivar <- cbind(bprs0, bprs1, bprs2, bprs3, bprs4, bprs5, bprs6) ~ age + sex + trial + edu + bmi + inkomen + job + adl + wzc + cdrsb0 + abpet0 # + taupet0 not estimated due to singularities


# multivariate ols
m_ols <- lm(
  form_multivar,
  data = dat
)

# multivariate gls
m_gls <- gls(
  model = form_multivar, # + taupet0 -> include only 1 biomarker, because of Singulary issues
  method = "ML",
  data = dat,
  na.action = na.exclude  # missing observations are a problem 
)

```


```{r}
summary(m_ols)
summary(m_gls)

```

...and have a closer look at the coefficients
```{r}

# lets look at the coefficients
round(m_ols$coefficients, 3)
round(m_gls$coefficients, 3)
```

Ok, the models have identical coefficients for the first outcome bprs0. This confirms that fitting a GLS model without specific (co)variance structures is equivalent to fitting an OLS model if no special variance or covariance structure is specified.
BUT gls() (in contrast to lm()) *drops* all additional outcomes, so we only get estimates for bprs0. lm() does this for us all in one function call.

But we would like to continue with the gls() fitted model.
Not only because it prints AIC etc. for Likelihood ratio tests.
But more importantly, because it allows us to play with the correlation and variance structures.

So we have to drop this approach and build the model with the long dataset, with a time variable to account for the repeated measurements.

#### Old: Very reduced model:
We try some stuff out, using only age as a predictor. 
Lets do it as asked in the assignment and predict the BPRS score (which is a psychiatric score). It would make more sense, of course, to predict the dementia score with the psychiatric condition and not the other way round. 

In this multivariate model, we will estimate the following predictors:

$Y_{i1} = beta_{0,0}(1-x_i) + \beta_{1,0}x_i + \epsilon_{i1} $
$Y_{i2} = beta_{0,1}(1-x_i) + \beta_{1,1}x_i + \epsilon_{i2} $
$Y_{i3} = beta_{0,2}(1-x_i) + \beta_{1,2}x_i + \epsilon_{i3} $
$Y_{i4} = beta_{0,3}(1-x_i) + \beta_{1,3}x_i + \epsilon_{i4} $
$Y_{i5} = beta_{0,4}(1-x_i) + \beta_{1,4}x_i + \epsilon_{i5} $
$Y_{i6} = beta_{0,5}(1-x_i) + \beta_{1,5}x_i + \epsilon_{i6} $
$Y_{i7} = beta_{0,6}(1-x_i) + \beta_{1,6}x_i + \epsilon_{i7} $

Although we name the time predictors starting with baseline measurement 0, let's keep the 1-based indexing for the model.
```{r eval=FALSE, include=FALSE}
# with nlme package ###

# start with uncorrelated errors
# (corresponding SAS argument would be type = VC)
bprs_mod0 <- gls(
  bprs ~ time + age, # - 1: we could also remove the intercept: then no absolute, not relative to bl
  weights = varIdent(form = ~ 1 | time),       # different variances per year
  method = "ML",
  data = dat_long_cmpl
)
summary(bprs_mod0)

# continue with unstructured errors: every time point has own variance, 
# and all year-pairs can have their own covariance 
bprs_mod1 <- gls(
  bprs ~ time + age,  # remove intercept, so absolute, not relative to bl
  correlation = corSymm(form = ~ 1 | patid),   # unstructured within-subject correlation
  weights = varIdent(form = ~ 1 | time),       # different variances per year
  method = "ML",
  data = dat_long_cmpl
)
summary(bprs_mod1)
getVarCov(bprs_mod1)

# now with interaction of time and age
bprs_mod2 <- gls(
  bprs ~ time * age,  
  correlation = corSymm(form = ~ 1 | patid),   # unstructured within-subject correlation
  weights = varIdent(form = ~ 1 | time),       # different variances per year
  method = "ML",
  data = dat_long_cmpl
)
summary(bprs_mod2)
getVarCov(bprs_mod2)


# now add time as our ordering variable: treat time as numeric, to respect the ordering
bprs_mod3 <- gls(
  bprs ~ time + age,  
  correlation = corSymm(form = ~ as.numeric(time) | patid),   # order the 
  weights = varIdent(form = ~ 1 | time),       # different variances per year
  method = "ML",
  data = dat_long_cmpl2  # using only subset of data with > 1 obs per subject
)
summary(bprs_mod3)
getVarCov(bprs_mod3)


```
We wanted to fit a model for our endpoint measured at 7 time points and fit the model with sex as predictor. That should give us 14 beta coefficients -> correct

Model 3:
The question is whether ordered factors would be more appropriate here than a numeric time variable. A factor cannot be handled for model estimation, though. 


Now what if we fit without an intercept?
```{r eval=FALSE, include=FALSE}
bprs_mod0noint <- gls(
    bprs ~ time + age - 1,  # remove intercept, so absolute, not relative to bl
    method = "ML",
    data = dat_long_cmpl
)
summary(bprs_mod0)

sum_bprs_mod0noint <- summary(bprs_mod0noint)

sum_bprs_mod0noint$corBeta
sum_bprs_mod0noint$corBeta

rm(bprs_mod0, bprs_mod1, bprs_mod2, bprs_mod3, bprs_mod0noint, sum_bprs_mod0noint)
```
All correlations get "eaten up" by the intercept, if we fit one. It represents the predicted value of our outcome (BPRS score) when all predictors are set to 0.
While a time = 0 makes sense here, the variable age is not that meaningful at age = 0. 
We could center age to make it interpretable: Then, the intercept would indicate the predicted outcome at the mean age of our sample at year 0 (baseline).




